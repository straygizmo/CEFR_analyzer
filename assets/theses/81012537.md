# 英語読解教材のCEFRレベルの推定：CVLAの妥当性評価

**Estimating the CEFR Levels of English Reading Materials: Evaluation of CVLA**

**著者:** 内田 諭（九州大学）・根岸雅史（東京外国語大学）  
**連絡先:** uchida@flc.kyushu-u.ac.jp, negishi@tufs.ac.jp

**出典:** Journal of Corpus-based Lexicology Studies, Vol. 3 (2020)  
**ISSN:** 2434-169X  
**発行日:** 2021-02-28  
**ページ:** 1-14

---

## 概要

本論文は，読解教材等のCEFRレベルを判定するアプリケーションであるCVLA(CEFR-based Vocabulary Level Analyzer)の妥当性について検証する。CEFRレベルが明示されている2種類のデータ（Council of Europeのテストサンプルとケンブリッジ英検の過去問）を用いて検証したところ，6値分類（A1, A2, B1, B2, C1, C2）で約53％の一致率であった。また，推定値が大きく外れていないことを確かめるために隣接レベルも含めて一致率を計算したところ，約81％という結果となった。この結果は，CVLAによる推定値が比較的安定していることを示しており，検証データの平均値である400語程度の入力があれば，ある程度の精度でCEFRレベルが判定できることが明らかとなった。

**キーワード:** CEFR，レベル推定，読解教材，CVLA

---

## 1. はじめに

外国語の習得において自分のレベルにあった入力を得ることは効率的に学習を進める上で非常に重要である。Krashen (1985)のインプット仮説では，「理解可能なインプット」(comprehensible input)の重要性を説いており，学習者にとって最適な入力は自身の現在の学習水準よりもわずかに高いものが最適であるとしている。学習者の現在の水準がiとすると，入力は「i+1」のものが適切であると比喩的に述べている。

学習のために重要な「理解可能なインプット」を得るためには，学習者のレベルを適切に把握することに加えて，入力となる素材のレベルを知ることが重要である。教師の立場から見ると，自分が受け持っている学習者のレベルを知り，そのレベルよりも少し高いレベルの教材を用いることが肝要であると言える。無論，外国語の習熟度を上げるためにはインプットのみならず，適切な分量のアウトプットやインタラクションも必要となるが（白井 2012），教材のレベルを把握するということは，学習者にとっても教師にとっても欠かすことはできない重要な側面である。

本論文では，英語の読解教材等を対象としてCEFR (Common European Framework of Reference for Languages)レベルを推定するプログラムであるCVLA (CEFR-based Vocabulary Level Analyzer)について，その推定値の妥当性を検証する。CVLAは，入力された英文から算出した4つの統計量を，CEFRレベル別に分類された英語教材のコーパスで測定した基準値と比較して，入力文のCEFR-Jレベル（日本の英語教育の文脈に合わせてCEFRレベルを細分化したもの）を推定するものである(Uchida & Negishi, 2018)。

以下ではレベル推定の先行研究としてLexile MeasureとText Inspectorについて概観した後，CVLAの概要について示し，CEFRレベルが明示されている2種類の英語の文章データを用いてCVLAの推定値の妥当性を測定する。

---

## 2. 先行研究

テキストレベルの推定には伝統的にリーダビリティが使用されてきた。例えば，中條・長谷川(2004)では，大学入試センター試験および40の大学の2次試験についてFlesch-Kincaid Formula, FORCAST Formulaなど複数のリーダビリティ指標を用いて検証し，センター試験は高校生にとって適切なレベル設定がなされている一方，大学個別の入試問題については大学によって差があり，一部の大学の英文は受験生にとって難易度が高すぎる傾向にあることを指摘した。

しかしながら，リーダビリティは，指標の計算がシラブル数，文長など比較的単純な指標を用いており，真に英語学習者に適切な数値となっているかどうかは判断が難しい。本節では，リーダビリティよりも一歩進んだ指標を提供する2つのアプリケーション（Lexile MeasureとText Inspector）について概観し，それぞれのアプリケーションを使った研究事例を紹介する。

### 2.1 Lexile Measure

Lexile MeasureはMetaMetrics社が開発した指標で，主に母語話者を対象として「自分のレベルにあった書籍を見つける」という目的で開発されたものである。この指標は，Semantic Difficultyの指標であるMean Log Word Frequency（対数化した単語頻度の平均）とSyntactic Complexityの指標であるMean Sentence Length（文の長さの平均）の2つの値から算出される(Lennon & Burdick, 2004/2014)。

詳細な数式は明示されていないが，Lexile Analyzerを用いることで手持ちのテキストのレベルを算出することができる。また，この指標にはLexile Reader Measure (LRM)とLexile Text Measure (LTM)があり，利用者は自身の指標（LRM）に合わせて書籍を探す（LTM）ことが想定されており，LTMとLRMの差が－100L～50Lあたりが最適なテキストであるとされている。

根岸(2015)は，Lexile Measureを使って高校英語教科書および入試問題の分析を実施した。その結果，学年進行とともにLexile Measureの値が高くなることが明らかとなり，さらに中学3年と高校1年では他の学年と比較して大きなギャップ（約300L）があることを指摘している。

大田(2016)もLexile Measureを使って中高の英語教科書を比較し，同様の結論を得ている。Smith and Turner (2018)は，CEFRレベルが付与されたGraded Readerを検証し，C2を除くそれぞれのレベルについておおよそのLexile Measureを推定し，A1 (230L-340L), A2 (425L-715L), B1 (588L-860L), B2 (598L-993L), C1 (760L-1200L)であったことを報告している。

### 2.2 Text Inspector

Text Inspectorはオンラインで利用できるテキスト分析ツールがある(Bax, 2012)。このツールでは，入力された英文に対して，文数，語数，文長，Type/Token Ratio，音節数，Flesch Reading Ease，Flesch-Kincaid Gradeなどの様々な指標に加えて，British National CorpusやCorpus of Contemporary American Englishにおける単語の頻度ランクごとのグラフなどが表示される。

また，Scorecardというセクションでは推定されるCEFRレベルも表示される（ただし有料版のみの機能）。Text InspectorのCEFRスコアの推定方法の詳細は示されていないが，ウェブサイトのHelpページによると，Lexical Diversity, English Vocabulary Profileでの語彙レベル，Type/token Ratio (TTR)，Average Sentence Lengthなどが関連する指標として示されており，これらを使って推定されていると考えられる。

また，独自のDレベル（Academic）も設けているという点も特徴的である。さらに，入力された英文で用いられているmetadiscourse markerの分析が可能で，attitude marker (admittedly, amazinglyなど)，hedge (almost, apparentlyなど)，booster (always, certainlyなど)の頻度を検証することができる。

Bax, Nakatsuhara, and Waller (2019)はText Inspectorを使って比較的習熟度の高い学習者（B2，C1，C2レベル）のライティングの分析を実施している。その結果，上位レベルの学習者のほうがmetadiscourse markerを使う頻度が下がるが，より幅広い表現を使う傾向があるということなどが指摘されている。このようにText Inspectorでは学習者の産出した英文も分析の対象とできることが特徴の1つであると言える。

### 2.3 まとめ

Lexile Measure, Text Inspectorは，旧来テキストレベルの推定に多く利用されてきたリーダビリティよりも詳細な分析を提供し，教材や学習者のライティングの分析にも応用可能である。しかしながら，Lexile値の算出方法やText InspectorのCEFRレベル判定に関するアルゴリズムは公開されておらず，学術的な検証が十分に実施できないという問題点がある。

また，日本の教材分析等を実施する場合は，CEFRよりもより詳細なレベル設定が設けられているCEFR-Jレベルとのリンクがあるほうが望ましい。以下では，本論文のリサーチクエスチョン（RQ）を述べた後，これらの問題点を有さないCVLAについて概要を説明し，その妥当性について検証を行う。

---

## 3. リサーチデザインと手法

### 3.1 研究目的とRQ

本論文の目的はUchida and Negishi (2018)によるCVLAの妥当性を評価することである。CVLAは後述するように明示的な4つの指標により入力文章のCEFR-Jレベルを推定するものである。本稿ではCVLAのリーディングモードを対象として，CVLAの推定レベルの妥当性についてCEFRレベルが明記されている文章を用いて検証する。

具体的には，以下の2つのリサーチクエスチョンを設定する。

**(1)** CVLAはCouncil of Europeが提示するCEFRレベルを示すサンプルテキストのレベルを正しく推定できるか

**(2)** CVLAはCEFRレベルが明示されているCambridge English Exams（ケンブリッジ英検）のリーディング素材についてレベルを正しく推定できるか

### 3.2 データ

本論文で使用する1つ目のデータは，Council of Europe (COE)がreading illustrative tasksとして示すものを利用する。Aptis (British Councilが実施する英語能力試験)，Cambridge English Language Assessmentの素材など，英語については全部で13の文章がある（A1:1件, A2:3件, B1:3件, B2:5件, C1:1件）。

本データは，97語～915語のテキストで，平均は466語である。これらのサンプルはPDFファイルで公開されており，その本文の部分のみを検証の対象とする。テストの難易度はタスクによっても変わりうるが，ここで示されている文章はそのレベルの学習者が読めることを想定しているものであるということから，当該レベルを代表すると考えることができる。

COEのデータに加えて，本稿ではCVLAの検証にケンブリッジ英検の過去問データを利用する。ケンブリッジ英検はKET (Key English Test; A2), PET (Preliminary English Test; B1), FCE (First Certificate in English; B2), CAE (Certificate of Advanced English; C1), CPE (Certificate of Proficiency in English; C2)の5種類があり，それぞれCEFRレベルが指定されている。

これらの試験問題からリーディングパッセージを取り出し，合計68件のデータを作成した（A2: 7件, B1: 14件, B2: 8件, C1: 20件, C2:19件）。なお，本データは，最小値161語～856語で，平均は392語である。

### 3.3 手法

本研究では上記の2種類のデータについて，(1)文書個別にCVLAで分析したもの，および(2)レベルごとにテキストをまとめてCVLAで分析したものを用いて妥当性を評価する。以下ではCVLAの概要とその分析例を示す。

#### 3.3.1 CVLAの概要

CVLAは入力テキストのCEFR-Jレベルを推定するオンラインアプリケーションである。CEFR-JはPreA1, A1.1, A1.2, A1.3, A2.1, A2.2, B1.1, B1.2, B2.1, B2.2, C1, C2の12段階に区切られており，CEFRよりも詳細な評価が可能な枠組みである（投野（編）2013）。リーディングモードとリスニングモードが用意されているが，本稿ではリーディングモードのみを検証の対象とする。

CVLAのCEFR-Jレベルの推定は，**ARI**, **VperSent**, **AvrDiff**, **BperA**の4つの指標を用いて行う。

- **ARI** とはAutomated Readability Indexの略で文字数や1文の単語数などから回帰的に推定されるリーダビリティ指標である (Senter & Smith 1967)
- **VperSent** (Verb per Sentence)は1文中に含まれる動詞の数の平均である。この指標は文の複雑さを間接的に表していると考えられる
- **AvrDiff** (Average Difficulty)は単語の難易度の平均である。CEFR-J Wordlistを参考に，A1の場合1，A2の場合2，B1の場合3，B2の場合4として文章中に含まれる内容語のレベルを平均したものである
- **BperA** はAレベルの内容語に対するBレベルの内容語の割合を表す

これら4つの指標について，内田(2015)で示したCEFRレベル別の教材コーパス（リーディングパート）を用いてそれぞれのレベルの平均値を示したものが下表である。

| Reading | ARI  | VperSent | AvrDiff | BperA |
|---------|------|----------|---------|-------|
| A1      | 5.73 | 1.49     | 1.31    | 0.08  |
| A2      | 7.03 | 1.82     | 1.41    | 0.12  |
| B1      | 10.00| 2.37     | 1.57    | 0.18  |
| B2      | 12.33| 2.88     | 1.71    | 0.26  |

この表からわかる通り，これら4つの指標はすべてCEFRレベルと比例関係にある。つまり，CEFRレベルが高くなれば，ARI，VperSent，AvrDiff，BperAも高くなるということである。

CVLAではA1=1, A2=2, B1=3, B2=4としてこれらの値から次のような回帰式を作成し，入力テキストの統計値からレベルの推定を行う。

```
CEFR_level_ARI = 0.4298*ARI - 1.27085
CEFR_level_VperSent = 2.1075*VperSent - 2.01
CEFR_level_AvrDiff = 7.2961*AvrDiff - 8.4442
CEFR_level_BperA = 16.3043*BperA - 0.1087
```

この結果，それぞれの指標からCEFRレベルが推定されるが，入力テキストの最終的なレベル判定はこれらの平均値から算出する。

また，CEFR-Jへの対応付けに関しては回帰によるレベル推定値をPre-A1 (<0.5), A1.1 (<0.84), A1.2 (<1.17), A1.3 (<1.5), A2.1 (<2), A2.2 (<2.5), B1.1 (<3), B1.2 (<3.5), B2.1 (<4), B2.2 (<4.5), C1 (<5), C2 (<6)のように分割して推定する(cf. Uchida and Negishi, 2018)。

CVLAの推定はCEFR-Jレベル（12段階）で出力されるが，本稿で用いるデータはCEFRレベル（6段階）が付与されているため，A1.1, A1.2, A1.3をA1，A2.1, A2.2をA2，B1.1, B1.2をB1，B2.1, B2.2をB2と読み替えて評価する（Pre A1は範囲外とする）。

#### 3.3.2 CVLAによる分析例

CVLAにCOEのA1のテキスト（Aptis）を入力して分析した結果の例では，ARI が1.83（PreA1相当），VperSentが2.08（A2.2相当），AvrDiffが1.16（PreA1相当），BperAが0.05（A1.1相当）とそれぞれ判定され，これらの平均値から算出したテキスト全体の推定レベルはA1.1という結果になった。このようにCVLAを利用することで明確な基準で入力テキストのCEFR-Jレベルを推定することが可能である。

---

## 4. 結果と考察

### 4.1 COEサンプルによるCVLAの検証(RQ1)

COEのサンプルパッセージによる分析結果を以下に示す。個別の文章ごとに分析した結果では，13文章中7文章（約54%）が一致という結果になった。この結果は，ランダム分類（6値分類のため約16.7％）をベースラインとして比較するとある程度の精度であるといえるが，語数が十分に多くない文章も含むため（最小97語，最大915語，平均466語），結果が安定しないことが考えられる。

つまり，語数が少ない場合，極端に短いまたは長い文が1つでもあればARIへの影響が大きくなり，判定結果がぶれることになる。また，語彙レベルに関しても文章の語数が少なければ1つ1つの語がAvrDiffに与える影響が過剰に大きくなると考えられる。

そこで文章をレベルごとに結合し，1つのテキストとして分析した。例えば，A2レベルには3つの文章があるが，これらすべてを1つのファイルにまとめてCVLAで分析した。分析の結果，C2以外のレベルではCVLAの推定値とCOEのサンプルのレベルが一致した（一致率80％）。

また，不一致となったB2はC1と判定されているが，最終スコア(4.68)はB1(2.95)とC1(5.24)の間に位置しており，レベルの連続性を捉えた結果となった。

### 4.2 ケンブリッジ英検のデータによるCVLAの検証(RQ2)

次にケンブリッジ英検のデータでの検証を行った。文章個別の分析では68文章中36件（約53％）が一致する結果となった。前節での検証同様，文章の長さによって結果が不安定になると考えられるため（最小値161語，最大値856語，平均392語），レベルごとにすべての文章を結合したものでの検証も実施した。

その結果，A2レベルはA1.3，C2レベルはC1と判定されたが，それ以外のレベルでは一致した（一致率60％）。前節と同じく，推定レベルの判定値は目標CEFRレベルと比例関係にあり，レベルの上下関係を捉えている。

具体的には，A1.3と判定されたA2の文章は1.47であり，B1の3.13よりも低い。また，ともにC1と判定されたCAE_C1 (4.76)，CPE_C2 (4.98)では，相対的にレベルが下である前者の判定値のほうが低く算出されている。

### 4.3 考察

2つのデータを用いた検証の結果，個別データの分析では全体で81件中43件が一致となり，約53％程度の精度で推定できることが明らかになった。ランダム分類と比較すると，ある程度の精度であるといえるが，不一致となった場合について，どの程度外れているかという点がCVLAの妥当性検証において重要な側面である。

レベルの一つ違いまでを正答とみなし（例えばB1が正答の場合でCVLAの結果がA2.2と推定した場合など），隣接レベルを含めて検証すると，COEでは10/13（約77%），ケンブリッジ英検では55/68 （約81%）がその範囲に含まれる。これらを合わせると全体で65/81（約80％）となる。

このことは，ほとんどの場合において推定結果が大きく外れていないことを示している。また，それぞれのデータについてレベルごとに文章をまとめた全体分析の結果を見ても，不一致であった部分のCEFR-Jレベルを判定する数値はレベルの上下関係を正しく捉えており，推定結果が大きくずれないことを示唆する。

一方，レベル別の正答率をみると，A1: 100%（1/1）, A2: 70%(7/10), B1: 約59%(10/17), B2: 約54%(7/13), C1: 約67％(14/21), C2: 約２１%(4/19)となっており，C2レベルの正答率が最も低い。このことはCVLAが依拠している教材コーパスのデータがB2までであり，C1，C2レベルについては回帰直線を伸ばして擬似的に推定していることが影響していると考えられる。この点はCVLAの将来的な改善課題の１つである。

今回検証に用いたデータは，81件あり，その平均語数は約404語（最小値97，最大値915，標準偏差235.3）であった。一致の場合の平均語数は410.2語，不一致の場合の平均語数は約396.5語（N=37）であり，一致のほうがやや語数が多かった。

標準偏差からはややばらつきのあるデータ群であることが読み取れるが，読解教材の場合，実験の結果から，およそ400語程度あれば約80％の場合でCEFRレベル1つのずれ幅内にとどまることが明らかとなり，ある程度の精度でCEFRレベルを判定できることが示唆される。

---

## 5. まとめ

本稿では，Uchida and Negishi (2018)で提案されたCVLAの妥当性について2つのデータソースを使って検証した。その結果，一致率は約53％，隣接レベルも含めた一致率は約80％となり，CVLAの推定値は概ね妥当なものであり，400語程度の入力があれば，大きくずれたレベルを判定することは少ないことが明らかとなった。

CVLAの特徴の一つとして，Lexile MeasureやText Inspectorとは違って指標を完全にオープンにしているという点が挙げられる。この性質を利用することで入力テキストをリライトする指針を得ることができる。例えば，ある入力テキストのVperSentが他の指標に比べて高い場合，受動態や関係節などを減らし，よりシンプルな文法構造にすることでテキストのレベルを下げることができる。

一方，AvrDiffやBperAが対象となる学習者や受験者よりも低い場合，単語をより上級なものに置き換えることで文章のレベルを上げることができる。CVLAのすべての指標はCEFRレベルが上がれば高くなるため，このように直感的に文章レベルの調整ができるのである。

CVLAの課題として，Cレベル以上の文章の判定精度を向上するということが挙げられる。今後はC1，C2レベルの教材コーパスを整備し，それぞれのレベルの統計値を算出したいと考えている。また，今回はリーディングのみの検証にとどまったため，リスニングスクリプトでの検証も必要である。さらに，テキストレベルとタスクレベルの関係については今後さらなる検討が必要であると考えている。

---

## 注

1. http://dd.kyushu-u.ac.jp/~uchida/cvla.html にて利用できる。また，https://cvla.langedu.jp/にて文ごとに指標を表示するversion 2を公開している。

2. 次のURLよりアクセス可能である（最終アクセス日：2021年1月10日）。https://www.coe.int/en/web/common-european-framework-reference-languages/reading-comprehension

3. ただし，CAEがGrade A評価の場合はC2として判定される。

4. ARIは次の数式で算出される。  
   4.71 (characters/words) + 0.5 (words/sentences) − 21.43

5. 『CEFR-J Wordlist Version 1.3』東京外国語大学投野由紀夫研究室. http://www.cefrj.org/download.html

---

## 付記

本論文の一部は2019年12月に横浜で実施されたBritish Council主催の国際会議New Directions 2019で発表したUchida, S. & Negishi, M. (2019) "Assigning CEFR and CEFRJ levels to Lexile measures: A corpus-based approach"に基づいている。

---

## 謝辞

本研究はJSPS科研費JP18H00693およびJP20H00095の助成を受けたものである。

---

## 引用文献

Bax, S. (2012). Text Inspector: Online text analysis tool. Available at: https://textinspector.com/.

Bax, S., Nakatsuhara, F., & Waller, D. (2019). Researching L2 writers' use of metadiscourse markers at intermediate and advanced levels. *System*, 83, 79-95.

中條清美・長谷川修治(2004)「語彙のカバー率とリーダビリティから見た大学英語入試問題の難易度」『日本大学生産工学部研究報告 B』 37，45-55.

Krashen, S. D. (1985). *The input hypothesis: Issues and implications*. Addison-Wesley Longman Ltd.

Lennon, C., & Burdick, H. (2004/2014). The Lexile framework as an approach for reading measurement and success. Electronic publication (http://cdn.lexile.com/cms_page_media/135/The%20Lexile%20Framework%20for%20Reading.pdf; accessed January 10, 2021).

根岸雅史(2015)「Lexile Measureによる中高大の英語教科書のテキスト難易度の研究」『ARCLE REVIEW』 9, 6-16.

大田悦子(2016)「Lexile Measureを用いた中高英語教科書の難易度比較」『白山英米文学』41, 1-20.

Senter, R. J., & Smith, E. A. (1967). Automated readability index. AMRL-TR-6620. Aerospace Medical Division, Wright Patterson AFB.

白井恭弘(2012)『英語教師のための第二言語習得論入門』大修館書店.

Smith, M., & Turner, J. (2018). The Common European Framework of Reference for Languages (CEFR) and the Lexile framework for reading bringing more precision to language learning. Electronic publication (https://metametricsinc.com/wp-content/uploads/2018/01/CEFR_1.pdf; accessed January 10, 2021).

内田諭(2015)「CEFRレベルに基づいた教材コーパス: レベル別基準特性の抽出に向けて」『英語コーパス研究』22, 87-99.

Uchida, S., & Negishi, M. (2018). Assigning CEFR-J levels to English texts based on textual features. In Tono, Y. & Isahara, H. (eds.) *Proceedings of Asia Pacific Corpus Linguistics Conference*, 4, 463-467.

投野由紀夫（編）(2013)『英語到達度指標 CEFR‐J ガイドブック』大修館書店.